# Papers-Stack
Keeping a track of research papers I've read.

Keys -> ||
:white_check_mark: : Done reading ||
:book: : In progress ||
:no_entry_sign: : Dropped ||


|No.| Status | Paper Name | Notes | Link | Year
|---| ---------------- | --------------- | --------------- | --- | --- |
|1| âœ… | WaveNet: A Generative Model for Raw Audio| notes |[arxiv](https://arxiv.org/abs/1609.03499) | 2016
| |                    | _Causal conv. layers with dilation. Autoregression model. Sequential inference_ | |
|2| âœ… | Fast Wavenet Generation Algorithm| notes |[arxiv](https://arxiv.org/abs/1611.09482) | 2016
| |                    | _WaveNet improvement. O(2<sup> L</sup>) -> O(L). Still sequential though. <br> Use queues to push & pop already computed states at each layer_ | |
|3| ðŸ“– | Parallel WaveNet: Fast High-Fidelity Speech Synthesis | | [arxiv](https://arxiv.org/abs/1711.10433) | 2017
| | â¬‡ï¸â¬†ï¸ |  | |
|4|ðŸ“•  | Improved Variational Inference with Inverse Autoregressive Flow || [arxiv](https://arxiv.org/abs/1606.04934) | 2016
| |â¬‡ï¸â¬†ï¸| â­ âœ”ï¸ Introduction to Normalizing Flows (ECCV2020 Tutorial)| | [video](https://www.youtube.com/watch?v=u3vVyFVU_lI)|
|5| âœ… | Deep Unsupervised Learning UC Berkeley lectures | | [course](https://sites.google.com/view/berkeley-cs294-158-sp20/home) |
| |    | âœ”ï¸ L1 - Introduction -> Types: 1. Generative models 2. Self-supervised models| | 1:10:00 |
| |    | âœ”ï¸ L2 - Autoregressive Models -> histogram. parameterized distribution. 1.)RNN based 2.)Masking based. 2.1)MADE 2.2)Masked ConvNets | | 2:27:23 |
| |    | âœ”ï¸ L3 - Flow Models -> Model output != p_theta(x); instead z=f_theta(x). z comes from a prob dist. Sampling is inverse of f_inverse_theta(x). <br> -> Autoregressive Flows:- Fast training; Slow sampling <br> -> Inverse Autoregressive Flow:- Slow training; Fast Sampling  | | 1:56:53 |
| |     |  | |
| |     |  | |
|.| ðŸš« | dummy | | link3 |
